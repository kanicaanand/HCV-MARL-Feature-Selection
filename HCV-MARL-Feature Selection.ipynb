{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMGi+az62w0c9dA4z8J/El",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kanicaanand/HCV-MARL-Feature-Selection/blob/main/HCV-MARL-Feature%20Selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nks416uGopIG",
        "outputId": "ef80ffe3-03c7-46b7-a8f3-3bf3643f833c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üñ•Ô∏è Using device: cpu\n",
            "Explicitly using CPU\n",
            "‚úÖ CPU-optimized environment ready!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import deque, Counter\n",
        "import time\n",
        "import pickle\n",
        "import warnings\n",
        "from copy import deepcopy\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "device = torch.device('cpu') # Explicitly set to CPU\n",
        "print(f\"üñ•Ô∏è Using device: {device}\")\n",
        "print(\"Explicitly using CPU\")\n",
        "\n",
        "# Set random seeds\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Create directories\n",
        "os.makedirs('saved_models', exist_ok=True)\n",
        "os.makedirs('plots_multi_agent_final', exist_ok=True)\n",
        "\n",
        "print(\"‚úÖ CPU-optimized environment ready!\")\n",
        "\n",
        "file_path= \"dataset bakshi nagar 1.xlsx\"\n",
        "def preprocess_data():\n",
        "\n",
        "  # Preprocess HCV dataset\n",
        "\n",
        "    print(f\"üìÅ Loading data from: {file_path}\")\n",
        "    df = pd.read_excel(file_path)\n",
        "    print(\"Available columns in dataset:\", df.columns.tolist())\n",
        "\n",
        "    # Map target variable\n",
        "    df['Status'] = df['Status'].map({\n",
        "        'HCV RNA Detected': 1,\n",
        "        'Negative': 0,\n",
        "        'Target Not Detected': 0,\n",
        "        '<Titer Min': 0\n",
        "    })\n",
        "    # Define expected features (clinical biomarkers only - no Age)\n",
        "    expected_features = ['Total Protein', 'Albumin', 'Globulin',\n",
        "                         'ALP', 'SGOT', 'SGPT', 'GGT', 'Bilrubin']\n",
        "    features = [f for f in expected_features if f in df.columns]\n",
        "\n",
        "    if len(features) < len(expected_features):\n",
        "        print(\"‚ö†Ô∏è Warning: Some features not found. Using:\", features)\n",
        "    if not features:\n",
        "        raise ValueError(\"‚ùå No valid features found in dataset.\")\n",
        "\n",
        "    print(\"NaN counts before imputation:\\n\", df[features].isna().sum())\n",
        "\n",
        "    # Impute missing values with median\n",
        "    for feature in features:\n",
        "        df[feature] = df[feature].fillna(df[feature].median())\n",
        "\n",
        "    if df[features].isna().any().any():\n",
        "        raise ValueError(\"‚ùå NaN values still present after imputation.\")\n",
        "\n",
        "    # Drop rows with NaN in 'Status'\n",
        "    df = df.dropna(subset=['Status'])\n",
        "\n",
        "    # Prepare features and target\n",
        "    X = df[features].values\n",
        "    y = df['Status'].values\n",
        "\n",
        "\n",
        "    # Feature scaling\n",
        "    scaler = MinMaxScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "\n",
        "    print(f\"‚úÖ Data preprocessing completed!\")\n",
        "    print(f\"üìä Final dataset: {X.shape[0]} samples, {X.shape[1]} features\")\n",
        "    print(f\"üéØ Class distribution: {np.unique(y, return_counts=True)}\")\n",
        "\n",
        "    return X, y, features, df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faa8d39e",
        "outputId": "15a397d3-e3af-4d44-e2b3-9d7abc9984b4"
      },
      "source": [
        "X, y, features, df = preprocess_data()\n",
        "\n",
        "print(\"\\nFirst 5 rows of processed features (X):\")\n",
        "print(X[:5])\n",
        "print(\"\\nShape of X:\", X.shape)\n",
        "\n",
        "print(\"\\nFirst 5 rows of processed target (y):\")\n",
        "print(y[:5])\n",
        "print(\"\\nShape of y:\", y.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Loading data from: dataset bakshi nagar 1.xlsx\n",
            "Available columns in dataset: ['S.no', 'Name', 'Gender', 'Age', 'Unnamed: 4', 'Status', 'Viral Load', 'Total Protein', 'Albumin', 'Globulin', 'ALP', 'SGOT', 'SGPT', 'GGT', 'Bilrubin']\n",
            "NaN counts before imputation:\n",
            " Total Protein    7\n",
            "Albumin          7\n",
            "Globulin         7\n",
            "ALP              7\n",
            "SGOT             7\n",
            "SGPT             7\n",
            "GGT              7\n",
            "Bilrubin         8\n",
            "dtype: int64\n",
            "‚úÖ Data preprocessing completed!\n",
            "üìä Final dataset: 938 samples, 8 features\n",
            "üéØ Class distribution: (array([0., 1.]), array([500, 438]))\n",
            "\n",
            "First 5 rows of processed features (X):\n",
            "[[8.12500000e-01 2.04081633e-02 2.32558140e-02 7.45573159e-03\n",
            "  1.02661597e-01 1.10192837e-02 3.75000000e-02 1.47783251e-04]\n",
            " [9.37500000e-01 8.16326531e-02 1.86046512e-01 2.70270270e-02\n",
            "  4.18250951e-02 4.82093664e-02 6.25000000e-02 1.97044335e-04]\n",
            " [8.62500000e-01 2.65306122e-01 1.16279070e-01 4.65983225e-03\n",
            "  3.04182510e-01 6.06060606e-02 2.18750000e-01 7.38916256e-03]\n",
            " [9.12500000e-01 1.42857143e-01 2.09302326e-01 1.11835974e-02\n",
            "  2.66159696e-01 9.64187328e-02 2.87500000e-01 1.03448276e-02]\n",
            " [1.00000000e+00 2.85714286e-01 3.02325581e-01 2.79589935e-03\n",
            "  5.70342205e-02 1.37741047e-02 8.12500000e-02 9.85221675e-05]]\n",
            "\n",
            "Shape of X: (938, 8)\n",
            "\n",
            "First 5 rows of processed target (y):\n",
            "[0. 0. 1. 1. 0.]\n",
            "\n",
            "Shape of y: (938,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def average_results_across_runs(all_runs_results):\n",
        "    \"\"\"Average results across multiple runs\"\"\"\n",
        "    if not all_runs_results:\n",
        "        return None\n",
        "\n",
        "    agent_names = list(all_runs_results[0].keys())\n",
        "    averaged_results = {}\n",
        "\n",
        "    for agent in agent_names:\n",
        "        averaged_results[agent] = {}\n",
        "\n",
        "        # Get classifier names\n",
        "        classifier_names = []\n",
        "        for key in all_runs_results[0][agent].keys():\n",
        "            if key not in ['features', 'n_features'] and isinstance(all_runs_results[0][agent][key], dict):\n",
        "                classifier_names.append(key)\n",
        "\n",
        "        # Average performance metrics\n",
        "        for clf in classifier_names:\n",
        "            metrics = ['accuracy', 'precision', 'recall', 'f1', 'f1_cv']\n",
        "            averaged_results[agent][clf] = {}\n",
        "\n",
        "            for metric in metrics:\n",
        "                values = []\n",
        "                for run_result in all_runs_results:\n",
        "                    if clf in run_result[agent] and metric in run_result[agent][clf]:\n",
        "                        values.append(run_result[agent][clf][metric])\n",
        "\n",
        "                if values:\n",
        "                    averaged_results[agent][clf][metric] = {\n",
        "                        'mean': np.mean(values),\n",
        "                        'std': np.std(values),\n",
        "                        'min': np.min(values),\n",
        "                        'max': np.max(values)\n",
        "                    }\n",
        "\n",
        "                    # Most frequent feature selection\n",
        "        feature_selections = []\n",
        "        for run_result in all_runs_results:\n",
        "            if 'features' in run_result[agent] and run_result[agent]['features']:\n",
        "                feature_selections.append(tuple(sorted(run_result[agent]['features'])))\n",
        "\n",
        "        # Find most common feature combination\n",
        "        if feature_selections:\n",
        "            most_common = Counter(feature_selections).most_common(1)[0][0]\n",
        "            averaged_results[agent]['features'] = list(most_common)\n",
        "            averaged_results[agent]['n_features'] = len(most_common)\n",
        "        else:\n",
        "            averaged_results[agent]['features'] = []\n",
        "            averaged_results[agent]['n_features'] = 0\n",
        "\n",
        "    return averaged_results\n",
        "\n",
        "print(\"‚úÖ Preprocessing and averaging functions defined!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zotns9kT3s6A",
        "outputId": "206f9170-f891-4525-d92c-40d7e6f7571c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Preprocessing and averaging functions defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import deque\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "class FeatureSelectionEnv:\n",
        "\n",
        "    #RL Environment for Feature Selection\n",
        "\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.n_features = X.shape[1]\n",
        "        self.state = np.zeros(self.n_features, dtype=int)\n",
        "        self.model = LogisticRegression(solver='liblinear', random_state=42, class_weight='balanced')\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = np.zeros(self.n_features, dtype=int)\n",
        "        return self.state.copy()\n",
        "\n",
        "    def step(self, action, agent_name):\n",
        "        feature_idx = action // 2\n",
        "        include = action % 2\n",
        "        self.state[feature_idx] = include\n",
        "        selected_features = np.where(self.state == 1)[0]\n",
        "\n",
        "        if len(selected_features) == 0:\n",
        "            return self.state.copy(), -1, False, 0\n",
        "\n",
        "        X_subset = self.X[:, selected_features]\n",
        "        self.model.fit(X_subset, self.y)\n",
        "        y_pred = self.model.predict(X_subset)\n",
        "        f1 = f1_score(self.y, y_pred, zero_division=0)\n",
        "\n",
        "        penalty = 0.04 if agent_name == 'Parsimonious' else 0.02\n",
        "        reward = f1 - penalty * len(selected_features)\n",
        "\n",
        "        if len(selected_features) > 4:\n",
        "            reward -= 0.1 * (len(selected_features) - 4)\n",
        "\n",
        "        done = False\n",
        "        return self.state.copy(), reward, done, f1\n",
        "\n",
        "\n",
        "class QLearningAgent:\n",
        "    def __init__(self, epsilon, alpha, gamma, n_actions):\n",
        "        self.epsilon = epsilon\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.n_actions = n_actions\n",
        "        self.q_table = {}\n",
        "        self.epsilon_decay = 0.995\n",
        "        self.min_epsilon = 0.1\n",
        "        self.max_q_table_size = 5000\n",
        "\n",
        "    def get_action(self, state):\n",
        "        state_tuple = tuple(state)\n",
        "        if state_tuple not in self.q_table:\n",
        "            self.q_table[state_tuple] = np.zeros(self.n_actions)\n",
        "\n",
        "        if len(self.q_table) > self.max_q_table_size:\n",
        "            q_sums = {s: np.sum(np.abs(qs)) for s, qs in self.q_table.items()}\n",
        "            sorted_states = sorted(q_sums.items(), key=lambda x: x[1])\n",
        "            for s, _ in sorted_states[:len(self.q_table) - self.max_q_table_size]:\n",
        "                del self.q_table[s]\n",
        "\n",
        "        if np.random.random() < self.epsilon:\n",
        "            return np.random.randint(self.n_actions)\n",
        "        return np.argmax(self.q_table[state_tuple])\n",
        "\n",
        "    def update(self, state, action, reward, next_state):\n",
        "        state_tuple = tuple(state)\n",
        "        next_state_tuple = tuple(next_state)\n",
        "\n",
        "        if state_tuple not in self.q_table:\n",
        "            self.q_table[state_tuple] = np.zeros(self.n_actions)\n",
        "        if next_state_tuple not in self.q_table:\n",
        "            self.q_table[next_state_tuple] = np.zeros(self.n_actions)\n",
        "\n",
        "        current_q = self.q_table[state_tuple][action]\n",
        "        next_max_q = np.max(self.q_table[next_state_tuple])\n",
        "        self.q_table[state_tuple][action] += self.alpha * (reward + self.gamma * next_max_q - current_q)\n",
        "\n",
        "    def decay_epsilon(self):\n",
        "        self.epsilon = max(self.min_epsilon, self.epsilon * self.epsilon_decay)\n",
        "\n",
        "class DQN(nn.Module):\n",
        "    def __init__(self, n_features, n_actions):\n",
        "        super(DQN, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_features, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, n_actions)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class DQNAgent:\n",
        "    def __init__(self, n_features, n_actions, epsilon, lr, gamma):\n",
        "        self.n_features = n_features\n",
        "        self.n_actions = n_actions\n",
        "        self.epsilon = epsilon\n",
        "        self.gamma = gamma\n",
        "        self.device = device\n",
        "\n",
        "        self.model = DQN(n_features, n_actions).to(self.device)\n",
        "        self.target_model = DQN(n_features, n_actions).to(self.device)\n",
        "        self.target_model.load_state_dict(self.model.state_dict())\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
        "        self.memory = deque(maxlen=2000)\n",
        "        self.epsilon_decay = 0.995\n",
        "        self.min_epsilon = 0.1\n",
        "\n",
        "        # Fixed batch size for CPU\n",
        "        self.batch_size = 64 # Was: 128 if torch.cuda.is_available() else 64\n",
        "        self.target_update_freq = 100\n",
        "        self.steps = 0\n",
        "        self.loss_history = []\n",
        "\n",
        "    def get_action(self, state):\n",
        "        if np.random.random() < self.epsilon:\n",
        "            return np.random.randint(self.n_actions)\n",
        "        state_tensor = torch.FloatTensor(state).unsqueeze(0).to(self.device)\n",
        "        with torch.no_grad():\n",
        "            q_values = self.model(state_tensor)\n",
        "        return q_values.argmax().item()\n",
        "\n",
        "    def store_transition(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state.copy(), action, reward, next_state.copy(), done))\n",
        "\n",
        "    def train(self):\n",
        "        if len(self.memory) < self.batch_size:\n",
        "            return\n",
        "        batch_indices = np.random.choice(len(self.memory), self.batch_size, replace=False)\n",
        "        batch = [self.memory[i] for i in batch_indices]\n",
        "        states, actions, rewards, next_states, dones = zip(*batch)\n",
        "\n",
        "        states = torch.FloatTensor(states).to(self.device)\n",
        "        actions = torch.LongTensor(actions).to(self.device)\n",
        "        rewards = torch.FloatTensor(rewards).to(self.device)\n",
        "        next_states = torch.FloatTensor(next_states).to(self.device)\n",
        "        dones = torch.FloatTensor(dones).to(self.device)\n",
        "\n",
        "        current_q_values = self.model(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            next_q_values = self.target_model(next_states).max(1)[0]\n",
        "            target_q_values = rewards + (1 - dones) * self.gamma * next_q_values\n",
        "\n",
        "        loss = nn.SmoothL1Loss()(current_q_values, target_q_values)\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
        "        self.optimizer.step()\n",
        "\n",
        "        self.steps += 1\n",
        "        self.loss_history.append(loss.item())\n",
        "\n",
        "        if self.steps % self.target_update_freq == 0:\n",
        "            self.target_model.load_state_dict(self.model.state_dict())\n",
        "\n",
        "\n",
        "    def decay_epsilon(self):\n",
        "        self.epsilon = max(self.min_epsilon, self.epsilon * self.epsilon_decay)\n",
        "\n",
        "class RandomAgent:\n",
        "    def __init__(self, n_actions):\n",
        "        self.n_actions = n_actions\n",
        "\n",
        "    def get_action(self, state):\n",
        "        return np.random.randint(self.n_actions)\n",
        "\n",
        "    def update(self, state, action, reward, next_state):\n",
        "        pass\n",
        "\n",
        "    def store_transition(self, state, action, reward, next_state, done):\n",
        "        pass\n",
        "\n",
        "    def train(self):\n",
        "        pass\n",
        "\n",
        "    def decay_epsilon(self):\n",
        "        pass\n",
        "\n",
        "print(\"üß† All agent classes defined!\")\n",
        "\n",
        "\n",
        "def train_agents(X, y, features, n_episodes=200, max_steps=15, run_seed=42):\n",
        "  # CPU-accelerated agent training\n",
        "    np.random.seed(run_seed)\n",
        "    torch.manual_seed(run_seed)\n",
        "    env = FeatureSelectionEnv(X, y)\n",
        "    n_actions = 2 * len(features)\n",
        "\n",
        "    agents = {\n",
        "        'Greedy': QLearningAgent(epsilon=0.2, alpha=0.15, gamma=0.9, n_actions=n_actions),\n",
        "        'Exploratory': QLearningAgent(epsilon=0.6, alpha=0.05, gamma=0.9, n_actions=n_actions),\n",
        "        'Parsimonious': DQNAgent(n_features=len(features), n_actions=n_actions, epsilon=0.4, lr=0.001, gamma=0.9),\n",
        "        'Random': RandomAgent(n_actions=n_actions)\n",
        "    }\n",
        "\n",
        "    rewards = {name: [] for name in agents}\n",
        "    accuracies = {name: [] for name in agents}\n",
        "    feature_selections = {name: [] for name in agents}\n",
        "    feature_evolution = {name: [] for name in agents}\n",
        "\n",
        "    for ep in range(n_episodes):\n",
        "        for name, agent in agents.items():\n",
        "            state = env.reset()\n",
        "            ep_reward = 0\n",
        "            ep_f1 = 0\n",
        "            ep_features = []\n",
        "\n",
        "            for step in range(max_steps):\n",
        "                action = agent.get_action(state)\n",
        "                next_state, reward, done, f1 = env.step(action, name)\n",
        "\n",
        "                if name != 'Random':\n",
        "                    if name == 'Parsimonious':\n",
        "                        agent.store_transition(state, action, reward, next_state, done)\n",
        "                        agent.train()\n",
        "                    else:\n",
        "                        agent.update(state, action, reward, next_state)\n",
        "\n",
        "                state = next_state\n",
        "                ep_reward += reward\n",
        "                ep_f1 = f1\n",
        "                ep_features.append(state.copy())\n",
        "\n",
        "            rewards[name].append(ep_reward)\n",
        "            accuracies[name].append(ep_f1)\n",
        "            feature_selections[name].append(state.copy())\n",
        "            feature_evolution[name].append(ep_features)\n",
        "            agent.decay_epsilon()\n",
        "\n",
        "        if (ep + 1) % 40 == 0:\n",
        "            print(f\"Episode {ep + 1}/{n_episodes} completed.\")\n",
        "\n",
        "    return agents, rewards, accuracies, feature_selections, feature_evolution\n",
        "\n",
        "def evaluate_agents_multi_classifier(agents, X_train, y_train, X_test, y_test, feature_selections, features, verbose=True):\n",
        "    # CPU-optimized multi-classifier evaluation\n",
        "    classifiers = {\n",
        "        'Logistic Regression': LogisticRegression(\n",
        "            solver='liblinear', random_state=42, class_weight='balanced',\n",
        "            max_iter=2000, n_jobs=-1\n",
        "        ),\n",
        "        'Decision Tree': DecisionTreeClassifier(\n",
        "            random_state=42, class_weight='balanced', max_depth=12\n",
        "        ),\n",
        "        'Random Forest': RandomForestClassifier(\n",
        "            n_estimators=100, random_state=42, class_weight='balanced',\n",
        "            max_depth=12, n_jobs=-1\n",
        "        ),\n",
        "        'XGBoost': xgb.XGBClassifier(\n",
        "            random_state=42, eval_metric='logloss', max_depth=6,\n",
        "            n_estimators=100, learning_rate=0.1,\n",
        "            # Fixed to CPU-only tree method\n",
        "            tree_method='hist',\n",
        "\n",
        "            n_jobs=-1 # Always use all available CPU cores\n",
        "        )\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for agent_name in agents:\n",
        "        if verbose:\n",
        "            print(f\"\\n{'='*60}\\nü§ñ Evaluating Agent: {agent_name}\\n{'='*60}\")\n",
        "\n",
        "        final_state = feature_selections[agent_name][-1]\n",
        "        selected_features = np.where(final_state == 1)[0]\n",
        "\n",
        "        if len(selected_features) == 0:\n",
        "            if verbose:\n",
        "                print(f\"‚ö†Ô∏è No features selected for {agent_name}\")\n",
        "            results[agent_name] = {clf_name: {'accuracy':0,'precision':0,'recall':0,'f1':0,'f1_cv':0} for clf_name in classifiers}\n",
        "            results[agent_name]['features'] = []\n",
        "            results[agent_name]['n_features'] = 0\n",
        "            continue\n",
        "\n",
        "        feature_names = [features[i] for i in selected_features]\n",
        "        if verbose:\n",
        "            print(f\"üìä Features ({len(selected_features)}): {feature_names}\")\n",
        "\n",
        "        X_train_sub = X_train[:, selected_features]\n",
        "        X_test_sub = X_test[:, selected_features]\n",
        "        results[agent_name] = {'features': feature_names, 'n_features': len(selected_features)}\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"{'Classifier':<20}{'Accuracy':<10}{'Precision':<10}{'Recall':<10}{'F1':<10}{'CV F1':<10}\")\n",
        "            print(\"-\" * 80)\n",
        "\n",
        "        for clf_name, clf in classifiers.items():\n",
        "            try:\n",
        "                f1_cv_scores = cross_val_score(clf, X_train_sub, y_train, cv=5, scoring='f1', n_jobs=-1)\n",
        "                f1_cv = f1_cv_scores.mean()\n",
        "\n",
        "                clf.fit(X_train_sub, y_train)\n",
        "                y_pred = clf.predict(X_test_sub)\n",
        "\n",
        "                acc = accuracy_score(y_test, y_pred)\n",
        "                prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "                rec = recall_score(y_test, y_pred, zero_division=0)\n",
        "                f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "                results[agent_name][clf_name] = {'accuracy':acc, 'precision':prec, 'recall':rec, 'f1':f1, 'f1_cv':f1_cv}\n",
        "\n",
        "                if verbose:\n",
        "                    print(f\"{clf_name:<20}{acc:<10.4f}{prec:<10.4f}{rec:<10.4f}{f1:<10.4f}{f1_cv:<10.4f}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                if verbose:\n",
        "                    print(f\"‚ùå Error with {clf_name}: {e}\")\n",
        "                results[agent_name][clf_name] = {'accuracy':0,'precision':0,'recall':0,'f1':0,'f1_cv':0}\n",
        "\n",
        "    return results\n",
        "\n",
        "print(\"üèÉ‚Äç‚ôÇÔ∏è Training and evaluation functions defined!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kR-m0Ll9X3F",
        "outputId": "17f970ad-8155-4e32-86bf-1f7f9893b1e6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß† All agent classes defined!\n",
            "üèÉ‚Äç‚ôÇÔ∏è Training and evaluation functions defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "  def evaluate_agents_multi_classifier(agents, X_train, y_train, X_test, y_test, feature_selections, features, verbose=True):\n",
        "    # CPU-optimized multi-classifier evaluation\n",
        "    classifiers = {\n",
        "        'Logistic Regression': LogisticRegression(\n",
        "            solver='liblinear', random_state=42, class_weight='balanced',\n",
        "            max_iter=2000, n_jobs=-1\n",
        "        ),\n",
        "        'Decision Tree': DecisionTreeClassifier(\n",
        "            random_state=42, class_weight='balanced', max_depth=12\n",
        "        ),\n",
        "        'Random Forest': RandomForestClassifier(\n",
        "            n_estimators=100, random_state=42, class_weight='balanced',\n",
        "            max_depth=12, n_jobs=-1\n",
        "        ),\n",
        "        'XGBoost': xgb.XGBClassifier(\n",
        "            random_state=42, eval_metric='logloss', max_depth=6,\n",
        "            n_estimators=100, learning_rate=0.1,\n",
        "            # Fixed to CPU-only tree method\n",
        "            tree_method='hist',\n",
        "\n",
        "            n_jobs=-1 # Always use all available CPU cores\n",
        "        )\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for agent_name in agents:\n",
        "        if verbose:\n",
        "            print(f\"\\n{'='*60}\\nü§ñ Evaluating Agent: {agent_name}\\n{'='*60}\")\n",
        "\n",
        "        final_state = feature_selections[agent_name][-1]\n",
        "        selected_features = np.where(final_state == 1)[0]\n",
        "\n",
        "        if len(selected_features) == 0:\n",
        "            if verbose:\n",
        "                print(f\"‚ö†Ô∏è No features selected for {agent_name}\")\n",
        "            results[agent_name] = {clf_name: {'accuracy':0,'precision':0,'recall':0,'f1':0,'f1_cv':0} for clf_name in classifiers}\n",
        "            results[agent_name]['features'] = []\n",
        "            results[agent_name]['n_features'] = 0\n",
        "            continue\n",
        "\n",
        "        feature_names = [features[i] for i in selected_features]\n",
        "        if verbose:\n",
        "            print(f\"üìä Features ({len(selected_features)}): {feature_names}\")\n",
        "\n",
        "        X_train_sub = X_train[:, selected_features]\n",
        "        X_test_sub = X_test[:, selected_features]\n",
        "        results[agent_name] = {'features': feature_names, 'n_features': len(selected_features)}\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"{'Classifier':<20}{'Accuracy':<10}{'Precision':<10}{'Recall':<10}{'F1':<10}{'CV F1':<10}\")\n",
        "            print(\"-\" * 80)\n",
        "\n",
        "        for clf_name, clf in classifiers.items():\n",
        "            try:\n",
        "                f1_cv_scores = cross_val_score(clf, X_train_sub, y_train, cv=5, scoring='f1', n_jobs=-1)\n",
        "                f1_cv = f1_cv_scores.mean()\n",
        "\n",
        "                clf.fit(X_train_sub, y_train)\n",
        "                y_pred = clf.predict(X_test_sub)\n",
        "\n",
        "                acc = accuracy_score(y_test, y_pred)\n",
        "                prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "                rec = recall_score(y_test, y_pred, zero_division=0)\n",
        "                f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "                results[agent_name][clf_name] = {'accuracy':acc, 'precision':prec, 'recall':rec, 'f1':f1, 'f1_cv':f1_cv}\n",
        "\n",
        "                if verbose:\n",
        "                    print(f\"{clf_name:<20}{acc:<10.4f}{prec:<10.4f}{rec:<10.4f}{f1:<10.4f}{f1_cv:<10.4f}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                if verbose:\n",
        "                    print(f\"‚ùå Error with {clf_name}: {e}\")\n",
        "                results[agent_name][clf_name] = {'accuracy':0,'precision':0,'recall':0,'f1':0,'f1_cv':0}\n",
        "\n",
        "    return results\n",
        "\n",
        "print(\"üèÉ‚Äç‚ôÇÔ∏è Training and evaluation functions defined!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49NCyYuU-ezM",
        "outputId": "a4a9b281-5675-4faf-bb6c-4281d0d30202"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÉ‚Äç‚ôÇÔ∏è Training and evaluation functions defined!\n"
          ]
        }
      ]
    }
  ]
}